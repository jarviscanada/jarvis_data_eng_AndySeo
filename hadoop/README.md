# Hadoop Project
Table of contents
* [Introduction](#Introduction)
* [Hadoop Cluster](#Hadoop Cluster)
* [Hive Project](#Hive Project)
* [Improvements](#Improvements)

# Introduction
The purpose of this project was to process data using big data platforms like
Apache Hadoop and evaluate different tools. We evaluated Core Hadoop components, 
including MapReduce, HDFS, and YARN. We provisioned the Hadoop cluster using
Google Cloud Platform with 1 master node and 2 worker nodes. Then we loaded/queried 
the data to answered business questions using Apache Hive and Zeppelin Notebook. 
During the process, we implemented various strategies to optimize our query
execution times and compared their performances to gain a better understanding of 
what is happening internally.

# Hadoop Cluster
- cluster architecture diagram
    - 1 master and 2 workers nodes
    - HDFS, YARN, Zeppelin, Hive (hive Server, hive metastore, RDBMS), etc.
- Big data tools you evaluated (e.g. MapReduce, YARN, HDFS, Hive, Zeppelin, etc..)
- hardware specifications

# Hive Project
- Discuss how you optimized Hive queries? (e.g. partitions, columnar, etc..)
- Post your Zeppelin Notebook screenshot here
    - Make sure your Notebook is nice and clean as hiring managers will visit your project
    - use `Full Page Screen Capture` chrome extension to capture a webpage as a picture

# Improvements
- at least three improvements